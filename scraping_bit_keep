
  // Let's scrape
  console.log("from individual scrapes");
  
  
// now go through all the websites where there are results:
var options = {
      url : linksjson[0].website,
      headers: {
        'User-Agent': 'request'
      }
    };
    console.log('after set options');

  // THIS IS THE LOOP
  for(website in linksjson)
  { 
    options.url = linksjson[website].website;
      request(options, function(error, response, html){
        if(error){console.log('There was an error', error)};
        if(!error){
          console.log("no error, scraping");
          var $ = cheerio.load(html);
          //Here, pick out the data and assign json
          $('table.sortable tbody tr').each(function(i, element){ 
            var children = $(this).children();
            if(children.eq(7).text() === "Eastleigh RC"){
              json.push({ "parkrun" : $('#primary h2').text(), "pos" : children.eq(0).text(), "parkrunner" :  children.eq(1).text(), "time": children.eq(2).text(), "agecat" : children.eq(3).text(), "agegrade" : children.eq(4).text(), "gender" : children.eq(5).text(), "genderpos" : children.eq(6).text(), "club" : children.eq(7).text(), "Note" : children.eq(8).text(), "TotalRuns" : children.eq(9).text()});   
            }   
          }); // end of each element in table sortable 
          console.log('here the file is read and json assigned');
          console.log("");
         }
      });
  }


      





// keep this is we need to clean the json file first:
// First clean the output.json
var json =[];
fs.writeFileSync('public/output.json', JSON.stringify(json, null, 4));
console.log("json cleaned / created");